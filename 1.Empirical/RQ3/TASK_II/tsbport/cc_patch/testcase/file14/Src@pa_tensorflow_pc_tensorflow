namespace tensorflow {
namespace {

auto* load_attempt_count = monitoring::Counter<2>::New("/tensorflow/cc/saved_model/load_attempt_count","The number of times a SavedModel was successfully loaded.", "model_path","status");
auto* load_latency = monitoring::Counter<1>::New("/tensorflow/cc/saved_model/load_latency","Latency in microseconds for SavedModels that were successfully loaded.","model_path");
auto* load_latency_by_stage = monitoring::Sampler<2>::New(
    {
        "/tensorflow/cc/saved_model/load_latency_by_stage",// metric name"Distribution of wall time spent (in microseconds) in each stage ""(restore graph from disk, run init graph op, etc) when loading the ""model","model_path","stage",},// Scale of 10, power of 1.8 with bucket count 33 (~20 minutes).monitoring::Buckets::Exponential(10, 1.8, 33));

constexpr char kLoadAttemptFail[] = "fail";
constexpr char kLoadAttemptSuccess[] = "success";

uint64 GetLatencyMicroseconds(const uint64 start_microseconds) {
  const uint64 end_microseconds = EnvTime::NowMicros();
  // Avoid clock skew.
  if (end_microseconds < start_microseconds) return 0;
  return end_microseconds - start_microseconds;
}

// Ensure that constant tensors loaded from the saved model have valid shape.
// Also ensure that constant nodes have a value assigned to them.
// TODO(b/154763635): this is temporary and will be replaced with a better audit
static Status ValidateSavedTensors(const GraphDef& graph_def) {
  for (const auto& node : graph_def.node()) {
    const auto node_iterator = node.attr().find("value");
    if (node_iterator != node.attr().end()) {
      AttrValue node_value = node_iterator->second;
      if (node_value.has_tensor()) {
        const PartialTensorShape node_shape(node_value.tensor().tensor_shape());
        if (node_shape.num_elements() < 0) {
          return errors::FailedPrecondition("Saved model contains node \"", node.name(), "\" (op \"",node.op(), "\") which initializes from a tensor with ",node_shape.num_elements(), " elements");
        }
      }
    } else if (node.op() == "Const") {
      return errors::FailedPrecondition("Saved model contains node \"", node.name(),"\" which is a constant tensor but no value has been provided");
    }
  }
  return Status::OK();
}

Tensor CreateStringTensor(const string& value) {
  Tensor tensor(DT_STRING, TensorShape({}));
  tensor.scalar<tstring>()() = value;
  return tensor;
}

void AddAssetsTensorsToInputs(const StringPiece export_dir,const std::vector<AssetFileDef>& asset_file_defs,std::vector<std::pair<string, Tensor>>* inputs) {
  if (asset_file_defs.empty()) {
    return;
  }
  for (auto& asset_file_def : asset_file_defs) {
    Tensor assets_file_path_tensor = CreateStringTensor(io::JoinPath(export_dir, kSavedModelAssetsDirectory, asset_file_def.filename()));
    inputs->push_back({asset_file_def.tensor_info().name(), assets_file_path_tensor});
  }
}
